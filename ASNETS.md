# ASNets
- Contact author: Daniel Fiser <danfis@danfis.cz>
- Code: `src/search/policy_fuzzing/asnets.*`
- Base classes: `ASNetsPolicy`, `ASNetsPolicyPruning`

`ASNetsPolicy` is an interface to the original ASNets implementation in Python.

1. First, a modified version of ASNets must be installed from the repository
https://gitlab.com/danfis/asnets, branch fd-interface:
The installation manual can be found in asnets/README.md, but for short:
1.1 sudo apt install python3-numpy python3-dev python3-pip python3-wheel \
  python3-venv flex bison build-essential autoconf libtool git \
  libboost-all-dev cmake
1.2 cd /path/to/this/dir/for/asnets
1.3 python3 -m venv asnet-env
1.4 source asnet-env/bin/activate
1.5 pip install --upgrade pip
1.6 pip install -e .

Note that Python version <3.8 is needed. So, the aforementioned steps work on
the latest Debian, but it's a little bit more complicated to make it work on
Ubuntu (but I managed to run it there too, so ask me if you struggle with it).

2. For the fast-downward part, python3-dev package is required, because the
interface is made as an embedded Python, i.e., fast-downward runs Python
interpreter internally and calls directly the python implementation of ASNets.

3. In order to successfuly use ASNetsPolicy class, fast-downward must be run
within the python virtual environment where asnets are installed, i.e.,
always run fast-downward only after calling the command 1.4.

4. Only one ASNets model can be used at a time, i.e., creating two instances
of ASNetsPolicy class with different arguments won't work.

5. After entering the python virtual environment (1.4), ASNetsPolicy class can
be instantiated with paths to domain and problem PDDL files, and a path to a
"snapshot" .pkl file generated by the ASNets -- this is the file with a
learned model. There are already some models in the repository
https://gitlab.com/danfis/asnets: Run `find problems -name model*.pkl` in the
top directory to see which domains has learned models (assuming the models are
valid for a different machine than they were learned at).

6. The API of ASNetsPolicy is pretty obvious: There is only one method
`apply_policy` that takes a state and applicable operators and returns the
operator according to the ASNets policy.

7. There is also ASNetsPolicyPruning class and the corresponding "asnets"
pruning method that can be used with a search algorithm, but it was created
mainly for the testing purposes. For debugging, I suppose, using directly
`ASNetsPolicy` is a better option.

8. ASNets and FD use different translators from PDDL, so some notes about the
internal implementation are necessary:

ASNetsPolicy class translates the FD state according to the names of facts.
Assuming both ASNets and FD uses a simple grounding using relaxed
reachability, the representation of states in both should be synchoronized.
That said, the code logs all ASNets facts that were not mapped to any FD fact
as "Unmapped ...". These print-outs should be checked after all experiments to
be sure nothing sinister happened. For example, for blocksworld we are getting:
Unmapped BoundProp('on', ('b1', 'b1'))
Unmapped BoundProp('on', ('b10', 'b10'))
....
which is fine, because these facts are not reachable anyway -- i.e., they will
be set to false in the input layer for all reachable states.

This also means that h^2 preprocessor shouldn't be used at all. I think using
h^2 pruning is (probably) fine, but the pruning with irrelevance analysis that
deletes irrelevant facts by backchaining from the goal may cause some
problems. It can modify preconditions of operators by removing facts that are
reachable (or even part of a plan) which (I think) would break the ASNets
models. So, we need to be cautious here.

The operators between ASNets and FD are also matched by their name, but I
don't think this can cause any problems. The only problematic scenario I can
foresee is using a domain with conditional effects that are compiled away by
multiplying them -- this would generated multiple operators with the same
name. Other than that, everything should be fine.
